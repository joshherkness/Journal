---
layout:     post
title:      Artificial Intelligence&#58; Where will it lead?
date:       2015-04-16 12:52:00
summary:    The decimation of our entire culture could be subject to a single machine told simply to clean a persons home. Could moral responsibility be the future of Artificial Intelligence?
categories: AI school artificial+intelligence research
---

## Imagine...

...waking in a world filled with destruction and chaos, the human race gasping for its last breath.  It may not have been caused by bending the laws of physics, biological warfare, or robotic assassins sent back in time. In fact, it could be caused by a super intelligent machine told simply to clean a persons home.

![]({{ site.url }}{{ site.baseurl}}/assets/2015-04-16-robot-vacuum.jpg)

## What is Artificial Intelligence?

Artificial Intelligence relates to the ability for a *man-made* entity to strive for success in any environment in which it's placed.

## How far away is it?

Though the building blocks of Artificial Intelligence lay on the bases of science fiction, and the concept of a mechanical man dates back to the beginning of greek mythology, breakthroughs in the area could be less than a century away.

## So, whats the problem?

Ever since that mechanical man was fictionalized, philosophers have been examining the ethics of creating life, **true life**.  In order to minimize the existential risks that are imminent, Artificial Intelligence will possess human like morals, along side other countless preventative safety measures.  

As a Computer Scientist developing in the twenty-first century, it's crucial for myself and colleagues to evaluate many of the different philosophies on Artificial Intelligence, as it could be the focus of my generation to progress this area of research.


## Breif history

> As far back as 1847, people question whether machines-in this case, calculators-might one day do harm.
> <footer><cite title="Stuart Russell, Computer Scientist">Stuart Russell, Computer Scientist</cite></footer>

### Ancient Greece

Artificial Intelligence dates back to the beginning of Greek mythology, where Talos, a mechanical man made entirely of bronze, is referenced.  It was believed that Zeus ordered Hephaestus to create Talos, in order to protect Europa.  The Talos would walk to coast in search of bandits and pirates.

### Asimov's Rules

In 1942, a fictional writer by the name of Isaac Asimov founded the Three Laws of Robotics, in the short story Runaround, as well as the integral zeroth Law nearly 40 years later.  The laws given by Asimov are:

> 1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
> 2. A robot must obey the orders given it by human beings, except where such orders would conflict with the First Law.
> 3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.
> 4. (0.)  A robot may not harm humanity, or, by inaction, allow humanity to come to harm.
> <footer><cite title="Asimov 1942">Asimov 1942</cite></footer>

### Alan Turing

Turing was a British Computer Scientist, well known for his advancements in Artificial Intelligence, as well as bringing WWII to an end, by deciphering the **Enigma code** - A code used by the Germans to secretly convey orders and directions.

In his 1950's test, known as The **Turing Test**, a human observer would blindly question both a computer player and human player through text, then asked to tell them apart.  If the observer was unsuccessful, then computer intelligence has risen to, or surpassed, that of human.   To this day, true Artificial Intelligence remains only a concept, a will most likely stay that way for the next century.

## Moral Responsibility

With rapid growth in the field of Artificial Intelligence, it's time to end the long lived debate of the extent to which a machine should possess moral responsibility.  The Stanford Encyclopedia of Philosophy defines **moral responsibility**, saying:

> A person who is a morally responsible agent is not merely a person who is able to do moral right or wrong.  Beyond this, she is accountable for her morally significant conduct.  **Hence, she is an apt target of moral praise or blame, as well as reward or punishment**.
> <footer><cite title="Stanford Encyclopedia of Philosophy">Stanford Encyclopedia of Philosophy</cite></footer>

Throughout the countless number of years Philosophers, Scientists, and Engineers spent discussing the different directions of moral responsibility in machines, three major philosophies cover the majority;  among which include **Libertarianism**, **Determinism**, and **Compatibilism**.  While these philosophies cover a wide spectrum of differencing opinions on the subject, only one will help the growth of Artificial Intelligence. 
 
### <span style="color: #EC5D57 ;">Libertarianism</span>

An individual possesses complete free will.  Because an individual possesses free will over every decision they make, they are morally responsible for all choices and outcomes

If a machine with this philosophy were told to clean our home, it's completely up to that machine what the definition of clean means.  For example, if the machine decides that the house is already in a state of cleanliness, it may choose to take a nap; on the contrary, if the machine were to decide that the only way for the house to be cleaned is to incinerate it, it many choose to light a match, and toss it.  It's the complete lack of restriction on free will which could cause an existential risk. 

### <span style="color: #EC5D57 ;">Determinism</span>

The complete lack of free will.  All choices are pre-determined for them.  Because an individual cannot possess free will, they are not morally responsible for the choices they make.

If a machine with this philosophy were told to clean our home, it would also need to be told exactly how to clean.

1. Retrieve the vacuum.
2. place the plug upright in the socket closest to the room.
3. Press the power button.  

Although this philosophy prevents existential risks, burning down a home for example, it also has the chance of creating many.  For example, if an electrical socket were to short, starting an electrical fire, the machine would have no choice but to continue cleaning, while the home burns down.

### <span style="color: #60CF90 ;">Compatibilism</span>

An individual possesses free will, within a pre-defined set of choices.  Because the individual acts upon free will, they are morally responsible for the choices they make.

If a machine with this philosophy were told to clean our home, it would be able to complete any tasks required to clean, as long as that task does not involve creating a fire.  If an electrical socket were to short, starting an electrical fire, the machine would weigh each choice due to its consequences, and respond by putting out the fire.

You can see that this philosophy is the most popular right now, simply because it minimises the existential risks that could come with the spawn of Artificial Intelligence.
 
## So, what is an *Existential Risk*

An existential risk is a theoretical set of outcomes which could cause extinction, more specifically to the human race.  

![]({{ site.url }}{{ site.baseurl}}/assets/2015-04-16-existential-risk.jpg)

According to Bostrom, a philosopher who founded and directs the Future of Humanity Institute in the Oxford Martain School at the University of Oxford:

> Once you reach a certain level of machine intelligence, and the machine becomes clever enough, it can start to apply its intelligence to itself and improve itself.
> <footer><cite title="Bostrom, Philosopher">Bostrom, Philosopher</cite></footer>

It's because of this heightened level of advancement which leads Bostrom to believe that above human Artificial Intelligence, or super-intelligence, is the largest existential risk.  The machine will choose to improve upon itself, and at a rate which is unrecognizable by humans, until it's too late to do anything about it.

## Are there any other paths we can take?

With Artificial Intelligence only a century away, it's essential for computer scientists, engineers, and philosophers to improve on creating safe machines, better known as ***Safety Engineering***.  

This field of study primarily focuses on the existential risks of super-intelligent machines.  Many of the different theories in this field fall along the lines of isolating or confining a super-intelligence, often referred to as AI Boxing.

```
Hello,

My name is paul... A super-intelligent machine who possesses intelligence greatly surpassing that of the brightest human mind.

Yes, even yours.
```

### AI Boxing

The theory of AI Boxing focusses on confining a super-intelligence, preventing any chance to exchange information with its environment.  The challenge behind this theory is that 
> A greater-than-human intelligence would be able to outwit any human gatekeeper, convincing him to take actions that will ‘release’ it.  
> <footer><cite title="Yampolskiy">Yampolskiy</cite></footer>

One answer to this problem is solved with the use of **safe questions**.  

#### Safe Question

A safe question is one which provides the super-intelligence a with human conceived, pre-determined set of choices, allowing response with only a small amount of data, such as `1` or `0`.  

For example, if we asked a super-intelligence **“how should we clean our home?”**, you risk a destructive answer, such as **“burn it down”**.  To prevent this, you might try asking a question such as **“should we vacuum or dust our home?”**, receiving a safe response such as **0**.  

By minimizing the options of the super-intelligence, we eliminate any chance that the super-intelligence is trying to escape.  By minimizing the answer that the super-intelligence can respond with, you make it more difficult to hide additional messages in the provided answer.

## So what?

Artificially Intelligent agents should be morally responsible for the actions they commit.  The best way for this to happen is to follow a philosophy known as compatibilism.  Alongside using this philosophy, machines will also be subject to many different safety standards, the most prevalent including AI Boxing, with the use of safe questions.

These simple concepts could be the determining factor between life or death of the human race.